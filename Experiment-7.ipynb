{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0e5679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simplest Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe287ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# This is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f347a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model maps an input to its encoded representation\n",
    "encoder = keras.Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b32d0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our encoded (32-dimensional) input\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# Create the decoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f94370e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ff1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "402e36bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "769ade2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3834 - val_loss: 0.1863\n",
      "Epoch 2/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1773 - val_loss: 0.1519\n",
      "Epoch 3/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1478 - val_loss: 0.1330\n",
      "Epoch 4/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1310 - val_loss: 0.1208\n",
      "Epoch 5/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1197 - val_loss: 0.1122\n",
      "Epoch 6/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1118 - val_loss: 0.1063\n",
      "Epoch 7/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1066 - val_loss: 0.1022\n",
      "Epoch 8/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1025 - val_loss: 0.0991\n",
      "Epoch 9/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0997 - val_loss: 0.0968\n",
      "Epoch 10/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0975 - val_loss: 0.0953\n",
      "Epoch 11/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0962 - val_loss: 0.0944\n",
      "Epoch 12/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0952 - val_loss: 0.0936\n",
      "Epoch 13/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0945 - val_loss: 0.0932\n",
      "Epoch 14/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0941 - val_loss: 0.0929\n",
      "Epoch 15/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0940 - val_loss: 0.0926\n",
      "Epoch 16/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0940 - val_loss: 0.0925\n",
      "Epoch 17/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 18/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 19/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0935 - val_loss: 0.0923\n",
      "Epoch 20/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0935 - val_loss: 0.0921\n",
      "Epoch 21/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0933 - val_loss: 0.0922\n",
      "Epoch 22/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0934 - val_loss: 0.0920\n",
      "Epoch 23/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0931 - val_loss: 0.0920\n",
      "Epoch 24/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0930 - val_loss: 0.0919\n",
      "Epoch 25/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0933 - val_loss: 0.0918\n",
      "Epoch 26/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 27/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0930 - val_loss: 0.0919\n",
      "Epoch 28/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0932 - val_loss: 0.0918\n",
      "Epoch 29/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0929 - val_loss: 0.0919\n",
      "Epoch 30/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 31/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0930 - val_loss: 0.0917\n",
      "Epoch 32/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0927 - val_loss: 0.0917\n",
      "Epoch 33/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 34/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 35/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0928 - val_loss: 0.0918\n",
      "Epoch 36/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0927 - val_loss: 0.0917\n",
      "Epoch 37/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 38/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0929 - val_loss: 0.0916\n",
      "Epoch 39/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 40/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0927 - val_loss: 0.0917\n",
      "Epoch 41/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 42/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 43/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0925 - val_loss: 0.0915\n",
      "Epoch 44/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0924 - val_loss: 0.0916\n",
      "Epoch 45/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0926 - val_loss: 0.0916\n",
      "Epoch 46/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 47/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0926 - val_loss: 0.0916\n",
      "Epoch 48/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0924 - val_loss: 0.0915\n",
      "Epoch 49/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 50/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0929 - val_loss: 0.0914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x169dcd090>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43d90150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277us/step\n"
     ]
    }
   ],
   "source": [
    "# Encode and decode some digits\n",
    "# Note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5accb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1667481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Sparsity Contraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87463849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "encoding_dim = 32\n",
    "\n",
    "input_img = keras.Input(shape=(784,))\n",
    "# Add a Dense layer with a L1 activity regularizer\n",
    "encoded = layers.Dense(encoding_dim, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd5a464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63fcfeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = keras.Input(shape=(784,))\n",
    "encoded = layers.Dense(128, activation='relu')(input_img)\n",
    "encoded = layers.Dense(64, activation='relu')(encoded)\n",
    "encoded = layers.Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = layers.Dense(64, activation='relu')(encoded)\n",
    "decoded = layers.Dense(128, activation='relu')(decoded)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51ce2822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.3388 - val_loss: 0.1651\n",
      "Epoch 2/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1567 - val_loss: 0.1378\n",
      "Epoch 3/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1361 - val_loss: 0.1264\n",
      "Epoch 4/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1262 - val_loss: 0.1199\n",
      "Epoch 5/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1202 - val_loss: 0.1156\n",
      "Epoch 6/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1161 - val_loss: 0.1117\n",
      "Epoch 7/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1123 - val_loss: 0.1080\n",
      "Epoch 8/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1087 - val_loss: 0.1054\n",
      "Epoch 9/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1055 - val_loss: 0.1038\n",
      "Epoch 10/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1038 - val_loss: 0.1012\n",
      "Epoch 11/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1018 - val_loss: 0.0995\n",
      "Epoch 12/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1002 - val_loss: 0.0984\n",
      "Epoch 13/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0990 - val_loss: 0.0970\n",
      "Epoch 14/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0980 - val_loss: 0.0962\n",
      "Epoch 15/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0969 - val_loss: 0.0954\n",
      "Epoch 16/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0965 - val_loss: 0.0950\n",
      "Epoch 17/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0958 - val_loss: 0.0943\n",
      "Epoch 18/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0950 - val_loss: 0.0940\n",
      "Epoch 19/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0946 - val_loss: 0.0936\n",
      "Epoch 20/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0937 - val_loss: 0.0926\n",
      "Epoch 21/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0933 - val_loss: 0.0919\n",
      "Epoch 22/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 23/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0919 - val_loss: 0.0913\n",
      "Epoch 24/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0916 - val_loss: 0.0905\n",
      "Epoch 25/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0910 - val_loss: 0.0900\n",
      "Epoch 26/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0905 - val_loss: 0.0898\n",
      "Epoch 27/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0902 - val_loss: 0.0892\n",
      "Epoch 28/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0899 - val_loss: 0.0887\n",
      "Epoch 29/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0895 - val_loss: 0.0885\n",
      "Epoch 30/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0892 - val_loss: 0.0884\n",
      "Epoch 31/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0888 - val_loss: 0.0882\n",
      "Epoch 32/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0885 - val_loss: 0.0876\n",
      "Epoch 33/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0885 - val_loss: 0.0874\n",
      "Epoch 34/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0883 - val_loss: 0.0875\n",
      "Epoch 35/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0878 - val_loss: 0.0871\n",
      "Epoch 36/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0879 - val_loss: 0.0869\n",
      "Epoch 37/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0874 - val_loss: 0.0868\n",
      "Epoch 38/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0870 - val_loss: 0.0866\n",
      "Epoch 39/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0871 - val_loss: 0.0866\n",
      "Epoch 40/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0866 - val_loss: 0.0867\n",
      "Epoch 41/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0867 - val_loss: 0.0861\n",
      "Epoch 42/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0863 - val_loss: 0.0860\n",
      "Epoch 43/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0863 - val_loss: 0.0858\n",
      "Epoch 44/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0862 - val_loss: 0.0857\n",
      "Epoch 45/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0862 - val_loss: 0.0855\n",
      "Epoch 46/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0859 - val_loss: 0.0854\n",
      "Epoch 47/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0858 - val_loss: 0.0854\n",
      "Epoch 48/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0857 - val_loss: 0.0855\n",
      "Epoch 49/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0856 - val_loss: 0.0854\n",
      "Epoch 50/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0856 - val_loss: 0.0849\n",
      "Epoch 51/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0854 - val_loss: 0.0850\n",
      "Epoch 52/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0852 - val_loss: 0.0848\n",
      "Epoch 53/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0851 - val_loss: 0.0844\n",
      "Epoch 54/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0847 - val_loss: 0.0846\n",
      "Epoch 55/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0848 - val_loss: 0.0844\n",
      "Epoch 56/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0843 - val_loss: 0.0840\n",
      "Epoch 57/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0845 - val_loss: 0.0839\n",
      "Epoch 58/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0842 - val_loss: 0.0837\n",
      "Epoch 59/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0840 - val_loss: 0.0836\n",
      "Epoch 60/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0840 - val_loss: 0.0839\n",
      "Epoch 61/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0840 - val_loss: 0.0834\n",
      "Epoch 62/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0836 - val_loss: 0.0834\n",
      "Epoch 63/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0836 - val_loss: 0.0832\n",
      "Epoch 64/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0833 - val_loss: 0.0833\n",
      "Epoch 65/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0834 - val_loss: 0.0830\n",
      "Epoch 66/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0833 - val_loss: 0.0831\n",
      "Epoch 67/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0832 - val_loss: 0.0831\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0833 - val_loss: 0.0828\n",
      "Epoch 69/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0832 - val_loss: 0.0829\n",
      "Epoch 70/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0830 - val_loss: 0.0825\n",
      "Epoch 71/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0830 - val_loss: 0.0828\n",
      "Epoch 72/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0830 - val_loss: 0.0826\n",
      "Epoch 73/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0828 - val_loss: 0.0826\n",
      "Epoch 74/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0829 - val_loss: 0.0827\n",
      "Epoch 75/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0829 - val_loss: 0.0826\n",
      "Epoch 76/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0826 - val_loss: 0.0822\n",
      "Epoch 77/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0828 - val_loss: 0.0824\n",
      "Epoch 78/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0826 - val_loss: 0.0824\n",
      "Epoch 79/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0826 - val_loss: 0.0825\n",
      "Epoch 80/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0825 - val_loss: 0.0822\n",
      "Epoch 81/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0824 - val_loss: 0.0822\n",
      "Epoch 82/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0824 - val_loss: 0.0822\n",
      "Epoch 83/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0825 - val_loss: 0.0825\n",
      "Epoch 84/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0825 - val_loss: 0.0822\n",
      "Epoch 85/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0823 - val_loss: 0.0822\n",
      "Epoch 86/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0820 - val_loss: 0.0821\n",
      "Epoch 87/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0821 - val_loss: 0.0822\n",
      "Epoch 88/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0824 - val_loss: 0.0819\n",
      "Epoch 89/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0822 - val_loss: 0.0819\n",
      "Epoch 90/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0819 - val_loss: 0.0818\n",
      "Epoch 91/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0821 - val_loss: 0.0820\n",
      "Epoch 92/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0822 - val_loss: 0.0818\n",
      "Epoch 93/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0820 - val_loss: 0.0817\n",
      "Epoch 94/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0819 - val_loss: 0.0817\n",
      "Epoch 95/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0818 - val_loss: 0.0817\n",
      "Epoch 96/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0820 - val_loss: 0.0817\n",
      "Epoch 97/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0819 - val_loss: 0.0819\n",
      "Epoch 98/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0819 - val_loss: 0.0815\n",
      "Epoch 99/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0820 - val_loss: 0.0816\n",
      "Epoch 100/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0817 - val_loss: 0.0819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1756c2990>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7f32741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afdf4d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "input_img = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28076cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b0245ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - loss: 0.3086 - val_loss: 0.1473\n",
      "Epoch 2/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - loss: 0.1424 - val_loss: 0.1283\n",
      "Epoch 3/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - loss: 0.1271 - val_loss: 0.1214\n",
      "Epoch 4/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 32ms/step - loss: 0.1201 - val_loss: 0.1149\n",
      "Epoch 5/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - loss: 0.1151 - val_loss: 0.1114\n",
      "Epoch 6/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - loss: 0.1117 - val_loss: 0.1085\n",
      "Epoch 7/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - loss: 0.1098 - val_loss: 0.1071\n",
      "Epoch 8/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - loss: 0.1074 - val_loss: 0.1052\n",
      "Epoch 9/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - loss: 0.1061 - val_loss: 0.1043\n",
      "Epoch 10/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - loss: 0.1048 - val_loss: 0.1027\n",
      "Epoch 11/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - loss: 0.1035 - val_loss: 0.1015\n",
      "Epoch 12/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - loss: 0.1022 - val_loss: 0.1009\n",
      "Epoch 13/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - loss: 0.1017 - val_loss: 0.0998\n",
      "Epoch 14/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 32ms/step - loss: 0.1007 - val_loss: 0.0990\n",
      "Epoch 15/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - loss: 0.1000 - val_loss: 0.0985\n",
      "Epoch 16/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 31ms/step - loss: 0.0994 - val_loss: 0.0983\n",
      "Epoch 17/50\n",
      "\u001b[1m231/469\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - loss: 0.0990"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorBoard\n\u001b[0;32m----> 3\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mfit(x_train, x_train,\n\u001b[1;32m      4\u001b[0m                 epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m      5\u001b[0m                 batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m      6\u001b[0m                 shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m                 validation_data\u001b[38;5;241m=\u001b[39m(x_test, x_test),\n\u001b[1;32m      8\u001b[0m                 callbacks\u001b[38;5;241m=\u001b[39m[TensorBoard(log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/tmp/autoencoder\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81505c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929af5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.Model(input_img, encoded)\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 8))\n",
    "for i in range(1, n + 1):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(encoded_imgs[i].reshape((4, 4 * 8)).T)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee319a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Application to image denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a112d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf28a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1, n + 1):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbbe773",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# At this point the representation is (7, 7, 32)\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa96ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequence to Sequence Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce84e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = ...  # Length of your sequences\n",
    "input_dim = ... \n",
    "latent_dim = ...\n",
    "\n",
    "inputs = keras.Input(shape=(timesteps, input_dim))\n",
    "encoded = layers.LSTM(latent_dim)(inputs)\n",
    "\n",
    "decoded = layers.RepeatVector(timesteps)(encoded)\n",
    "decoded = layers.LSTM(input_dim, return_sequences=True)(decoded)\n",
    "\n",
    "sequence_autoencoder = keras.Model(inputs, decoded)\n",
    "encoder = keras.Model(inputs, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f278d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3040243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim = 28 * 28\n",
    "intermediate_dim = 64\n",
    "latent_dim = 2\n",
    "\n",
    "inputs = keras.Input(shape=(original_dim,))\n",
    "h = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = layers.Dense(latent_dim)(h)\n",
    "z_log_sigma = layers.Dense(latent_dim)(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78302437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10462b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoder\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "# Create decoder\n",
    "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = layers.Dense(original_dim, activation='sigmoid')(x)\n",
    "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = keras.Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde17a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
    "reconstruction_loss *= original_dim\n",
    "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd4411",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "vae.fit(x_train, x_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaca01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# We will sample n points within [-15, 15] standard deviations\n",
    "grid_x = np.linspace(-15, 15, n)\n",
    "grid_y = np.linspace(-15, 15, n)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = decoder.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1158b4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
